{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aliasgharshinwari/emgaxo/blob/main/emgaxo_full_tutorial_SW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLQHIohMQ9EK",
        "outputId": "60d6950b-e1f9-43ff-83f2-f6a51c688ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local/miniconda\n",
            "Unpacking bootstrapper...\n",
            "Unpacking payload...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local/miniconda\n"
          ]
        }
      ],
      "source": [
        "# Clean any broken or old conda installs\n",
        "!rm -rf /usr/local/miniconda\n",
        "\n",
        "# Reinstall Miniconda cleanly\n",
        "!wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -b -p /usr/local/miniconda\n",
        "!rm Miniconda3-latest-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize conda in this session\n",
        "import sys\n",
        "sys.path.append('/usr/local/miniconda/lib/python3.10/site-packages')\n",
        "!eval \"$(/usr/local/miniconda/bin/conda shell.bash hook)\"\n",
        "\n",
        "# Accept Anaconda Terms of Service (for main + r channels)\n",
        "!/usr/local/miniconda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!/usr/local/miniconda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
        "\n",
        "# Create a new environment with Python 3.10.12\n",
        "!/usr/local/miniconda/bin/conda create -y -n py310 python=3.10.12\n",
        "\n",
        "# Show environments\n",
        "!/usr/local/miniconda/bin/conda env list\n",
        "\n",
        "# Verify Python version in the new env\n",
        "!/usr/local/miniconda/bin/conda run -n py310 python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvwLCXNORD9P",
        "outputId": "36b0f112-a8aa-4741-ea83-d8504c1ac8d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\n",
            "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n",
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/miniconda/envs/py310\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10.12\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    python-3.10.12             |       h955ad1f_0        26.8 MB\n",
            "    setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n",
            "    wheel-0.45.1               |  py310h06a4308_0         115 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        28.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n",
            "  libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
            "  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n",
            "  pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n",
            "  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
            "  python             pkgs/main/linux-64::python-3.10.12-h955ad1f_0 \n",
            "  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n",
            "  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
            "  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
            "  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
            "  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
            "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.12       | 26.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "setuptools-80.9.0    | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "python-3.10.12       | 26.8 MB   | :   0% 0.0005827226849630587/1 [00:00<04:15, 255.78s/it]\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:01,  1.17s/it]\u001b[A\u001b[A\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  1.17s/it]                \u001b[A\u001b[A\n",
            "python-3.10.12       | 26.8 MB   | :  23% 0.23017546056040822/1 [00:00<00:00,  1.13it/s]   \n",
            "\n",
            "wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  3.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "python-3.10.12       | 26.8 MB   | : 100% 1.0/1 [00:00<00:00,  1.60it/s]\n",
            "setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.47it/s]\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate py310\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\n",
            "# conda environments:\n",
            "#\n",
            "# * -> active\n",
            "# + -> frozen\n",
            "base                     /usr/local/miniconda\n",
            "py310                    /usr/local/miniconda/envs/py310\n",
            "\n",
            "Python 3.10.12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] = \"/usr/local/miniconda/envs/py310/bin:\" + os.environ['PATH']\n",
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm9W-rm6RHCo",
        "outputId": "22d770eb-2cb3-42db-9449-cb280801d9e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf emgaxo/"
      ],
      "metadata": {
        "id": "sggpq77hRHyK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Aliasgharshinwari/emgaxo.git\n",
        "!cd emgaxo\n",
        "!pip install emgaxo/\n",
        "!python3 -m venv emgaxo/emgaxo_env\n",
        "!source emgaxo/emgaxo_env/bin/activate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juR7LemQRKPk",
        "outputId": "7b08bd4e-b717-4e3e-8ac6-06aea79a2607"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'emgaxo'...\n",
            "remote: Enumerating objects: 617, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 617 (delta 34), reused 32 (delta 13), pack-reused 548 (from 2)\u001b[K\n",
            "Receiving objects: 100% (617/617), 2.27 MiB | 6.78 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n",
            "Processing ./emgaxo\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emgaxo\n",
            "  Building wheel for emgaxo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emgaxo: filename=emgaxo-0.1.1-py3-none-any.whl size=14147 sha256=e5910a1b80b05adf97d47ef7ebdc74d1cc7562bbba7b8e530afaaa45a3aa8267\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gvr9gmp7/wheels/bb/5b/35/75f76a02a7d869f8f215b5f4143cc9965bf41ce8bfecb305f4\n",
            "Successfully built emgaxo\n",
            "Installing collected packages: emgaxo\n",
            "Successfully installed emgaxo-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPJXX26cRMvE",
        "outputId": "403a1615-6a33-4a3f-ae48-bfe4f8d22894"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r emgaxo/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArIQeL3FRRr-",
        "outputId": "c535da5c-bf9a-43bc-c80b-e07fe1a8dca4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.14.1 (from -r emgaxo/requirements.txt (line 1))\n",
            "  Using cached tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow-estimator==2.14.0 (from -r emgaxo/requirements.txt (line 2))\n",
            "  Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnx==1.17.0 (from -r emgaxo/requirements.txt (line 3))\n",
            "  Using cached onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime-gpu==1.21.0 (from -r emgaxo/requirements.txt (line 4))\n",
            "  Using cached onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting onnxruntime_extensions==0.14.0 (from -r emgaxo/requirements.txt (line 5))\n",
            "  Using cached onnxruntime_extensions-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting tf2onnx==1.16.1 (from -r emgaxo/requirements.txt (line 6))\n",
            "  Using cached tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting transformers==4.49.0 (from -r emgaxo/requirements.txt (line 7))\n",
            "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting pycuda==2025.1.2 (from -r emgaxo/requirements.txt (line 8))\n",
            "  Using cached pycuda-2025.1.2-cp310-cp310-linux_x86_64.whl\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1)) (80.9.0)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu==1.21.0->-r emgaxo/requirements.txt (line 4))\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting sympy (from onnxruntime-gpu==1.21.0->-r emgaxo/requirements.txt (line 4))\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting requests (from tf2onnx==1.16.1->-r emgaxo/requirements.txt (line 6))\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Collecting filelock (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pytools>=2011.2 (from pycuda==2025.1.2->-r emgaxo/requirements.txt (line 8))\n",
            "  Using cached pytools-2025.2.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting platformdirs>=2.2.0 (from pycuda==2025.1.2->-r emgaxo/requirements.txt (line 8))\n",
            "  Using cached platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mako (from pycuda==2025.1.2->-r emgaxo/requirements.txt (line 8))\n",
            "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0->-r emgaxo/requirements.txt (line 7))\n",
            "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->tf2onnx==1.16.1->-r emgaxo/requirements.txt (line 6))\n",
            "  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->tf2onnx==1.16.1->-r emgaxo/requirements.txt (line 6))\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->tf2onnx==1.16.1->-r emgaxo/requirements.txt (line 6))\n",
            "  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->tf2onnx==1.16.1->-r emgaxo/requirements.txt (line 6))\n",
            "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1)) (0.45.1)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda==2025.1.2->-r emgaxo/requirements.txt (line 8))\n",
            "  Using cached siphash24-1.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.1->-r emgaxo/requirements.txt (line 1))\n",
            "  Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu==1.21.0->-r emgaxo/requirements.txt (line 4))\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime-gpu==1.21.0->-r emgaxo/requirements.txt (line 4))\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "Using cached onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "Using cached onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "Using cached onnxruntime_extensions-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Using cached tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "Using cached ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Using cached grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Using cached tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "Using cached google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
            "Using cached cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
            "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "Using cached wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (76 kB)\n",
            "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached h5py-3.15.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached pytools-2025.2.5-py3-none-any.whl (98 kB)\n",
            "Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "Using cached regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Using cached siphash24-1.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (103 kB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
            "Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached filelock-3.20.1-py3-none-any.whl (16 kB)\n",
            "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: onnxruntime_extensions, mpmath, libclang, flatbuffers, wrapt, urllib3, typing-extensions, tqdm, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sympy, six, siphash24, safetensors, regex, pyyaml, pyasn1, protobuf, platformdirs, packaging, opt-einsum, oauthlib, numpy, markupsafe, markdown, keras, idna, humanfriendly, hf-xet, gast, fsspec, filelock, charset_normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pytools, pyasn1-modules, onnx, ml-dtypes, mako, h5py, grpcio, google-pasta, coloredlogs, astunparse, tf2onnx, requests-oauthlib, pycuda, onnxruntime-gpu, huggingface-hub, google-auth, tokenizers, google-auth-oauthlib, transformers, tensorboard, tensorflow\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/62\u001b[0m [tensorflow]\n",
            "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 cachetools-6.2.4 certifi-2025.11.12 charset_normalizer-3.4.4 coloredlogs-15.0.1 filelock-3.20.1 flatbuffers-25.12.19 fsspec-2025.12.0 gast-0.7.0 google-auth-2.45.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 hf-xet-1.2.0 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 keras-2.14.0 libclang-18.1.1 mako-1.3.10 markdown-3.10 markupsafe-3.0.3 ml-dtypes-0.2.0 mpmath-1.3.0 numpy-1.26.4 oauthlib-3.3.1 onnx-1.17.0 onnxruntime-gpu-1.21.0 onnxruntime_extensions-0.14.0 opt-einsum-3.4.0 packaging-25.0 platformdirs-4.5.1 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycuda-2025.1.2 pytools-2025.2.5 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rsa-4.9.1 safetensors-0.7.0 siphash24-1.8 six-1.17.0 sympy-1.14.0 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.2.0 tf2onnx-1.16.1 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.49.0 typing-extensions-4.15.0 urllib3-2.6.2 werkzeug-3.1.4 wrapt-1.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow[and-cuda]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ej_urked5fd",
        "outputId": "07707cf2-fa54-4091-c2c8-5361a28f807c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (2.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.15.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.14.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.76.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.14.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.7.0.84 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.16.5 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvcc-cu11==11.8.89 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tensorrt==8.5.3.1 (from tensorflow[and-cuda])\n",
            "  Downloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl.metadata (721 bytes)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.45.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.10)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.32.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.1.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.3.1)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.0.3)\n",
            "Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl (210.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:22\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl (549.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m  \u001b[33m0:01:07\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, tensorrt\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [tensorrt]\n",
            "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.16.5 tensorrt-8.5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/01_mnist_fully_connected_model_training.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4iNEO2ORSne",
        "outputId": "eff3a0bb-3b9a-4d60-e7c3-cdb8097c71f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-20 11:17:36.502288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-12-20 11:17:36.502353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-12-20 11:17:36.502399: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-12-20 11:17:36.536841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-20 11:17:38.898780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:38.966582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:38.966817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:38 [INFO] Enabled memory growth on 1 GPU(s).\n",
            "2025-12-20 11:17:39.332215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.332492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.332682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.422891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.423120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.423295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:17:39.423432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Epoch 1/20\n",
            "2025-12-20 11:17:42.244093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c6c89e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-12-20 11:17:42.244144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-12-20 11:17:42.286278: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-20 11:17:42.376568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2025-12-20 11:17:42.504986: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.3548 - accuracy: 0.8874\n",
            "Epoch 1: val_loss improved from inf to 0.13284, saving model to models/best_model.h5\n",
            "/usr/local/miniconda/envs/py310/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "469/469 [==============================] - 6s 5ms/step - loss: 0.3530 - accuracy: 0.8880 - val_loss: 0.1328 - val_accuracy: 0.9599 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9651\n",
            "Epoch 2: val_loss improved from 0.13284 to 0.10186, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9651 - val_loss: 0.1019 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9762\n",
            "Epoch 3: val_loss improved from 0.10186 to 0.08662, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.9762 - val_loss: 0.0866 - val_accuracy: 0.9725 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9838\n",
            "Epoch 4: val_loss improved from 0.08662 to 0.08496, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0535 - accuracy: 0.9837 - val_loss: 0.0850 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9861\n",
            "Epoch 5: val_loss improved from 0.08496 to 0.08113, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0811 - val_accuracy: 0.9737 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9891\n",
            "Epoch 6: val_loss did not improve from 0.08113\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0861 - val_accuracy: 0.9758 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "457/469 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9907\n",
            "Epoch 7: val_loss did not improve from 0.08113\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0853 - val_accuracy: 0.9764 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9964\n",
            "Epoch 8: val_loss improved from 0.08113 to 0.07654, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0765 - val_accuracy: 0.9804 - lr: 5.0000e-04\n",
            "Epoch 9/20\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
            "Epoch 9: val_loss improved from 0.07654 to 0.07172, saving model to models/best_model.h5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0717 - val_accuracy: 0.9831 - lr: 5.0000e-04\n",
            "Epoch 10/20\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9987\n",
            "Epoch 10: val_loss did not improve from 0.07172\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0853 - val_accuracy: 0.9805 - lr: 5.0000e-04\n",
            "Epoch 11/20\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 11: val_loss did not improve from 0.07172\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0845 - val_accuracy: 0.9807 - lr: 5.0000e-04\n",
            "Epoch 12/20\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
            "Epoch 12: val_loss did not improve from 0.07172\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0841 - val_accuracy: 0.9822 - lr: 2.5000e-04\n",
            "2025-12-20 11:18:09 [INFO] Final test accuracy: 98.31%\n",
            "2025-12-20 11:18:09.686193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.686378: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2025-12-20 11:18:09.686474: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2025-12-20 11:18:09.686822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.687015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.687168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.687363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.687529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.687675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2025-12-20 11:18:09.734902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.735132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.735286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.735487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.735679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.735814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2025-12-20 11:18:09.740453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.740639: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2025-12-20 11:18:09.740731: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2025-12-20 11:18:09.741065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.741253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.741404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.741625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.741798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-20 11:18:09.741929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2025-12-20 11:18:09 [INFO] Using tensorflow=2.14.1, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
            "2025-12-20 11:18:09 [INFO] Using opset <onnx, 15>\n",
            "2025-12-20 11:18:09 [INFO] Computed 0 values for constant folding\n",
            "2025-12-20 11:18:09 [INFO] Optimizing ONNX model\n",
            "2025-12-20 11:18:09 [INFO] After optimization: Identity -2 (2->0)\n",
            "2025-12-20 11:18:09 [INFO] Successfully exported ONNX model to: models/mnist_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m onnxruntime.quantization.preprocess --input ./models/mnist_model.onnx --output ./models/mnist_model_infer.onnx"
      ],
      "metadata": {
        "id": "ur4GaApgRVLS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/02_mnist_static_quantization.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNLU4B5mRX0w",
        "outputId": "451f22b4-df04-43dc-c9bf-0fa19de72ad5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-20 11:18:23.983733: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-12-20 11:18:23.983783: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-12-20 11:18:23.983824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-12-20 11:18:23.991582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Model successfully quantized to ./models/mnist_model_quantized_qgemm_uint.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/03_accuracy_tester_gemm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvd9F4xTRajF",
        "outputId": "0b0afabf-a249-4c07-ea3c-dfa534a97a59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MNIST test data already exists.\n",
            "Average inference time: 0.0102 ms\n",
            "Accuracy: 98.32%\n",
            "Precision: 0.9832\n",
            "Recall: 0.9832\n",
            "F1 Score: 0.9832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/04_accuracy_tester_qgemm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3hClb6bRdEF",
        "outputId": "0e821ab3-435e-4fd0-c5b0-b7a522d211bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;93m2025-12-20 11:18:34.035274282 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 2 Memcpy nodes are added to the graph tf2onnx for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
            "\u001b[0;93m2025-12-20 11:18:34.035507938 [W:onnxruntime:, session_state.cc:1263 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
            "\u001b[0;93m2025-12-20 11:18:34.035522045 [W:onnxruntime:, session_state.cc:1265 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
            "Average inference time: 0.0070 ms\n",
            "Accuracy: 96.97%\n",
            "Precision: 0.9705\n",
            "Recall: 0.9697\n",
            "F1 Score: 0.9698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/05_modifying_qgemm_with_ApproxQGemm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2AakL1qRfjL",
        "outputId": "48016a2d-8c7d-4142-d88d-3e52863a27ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG modify_model] INIT_Value = 68719476735\n",
            "1 Successfully replaced sequential/dense/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "2 Successfully replaced sequential/dense_1/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense_1/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "3 Successfully replaced sequential/dense_2/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense_2/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "4 Successfully replaced sequential/dense_3/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense_3/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "5 Successfully replaced sequential/dense_4/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense_4/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "6 Successfully replaced sequential/dense_5/MatMul/MatMulAddFusion_quant (QGemm) with sequential/dense_5/MatMul/MatMulAddFusion_quant (ApproxQGemm)\n",
            "68719476735\n",
            "Model successfully saved to ./models/mnist_model_quantized_qgemm_uint_modified.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/06_removing_quantize_linear.py"
      ],
      "metadata": {
        "id": "9xCgfYcMRi-7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall onnxruntime onnxruntime-gpu -y\n",
        "!pip install onnxruntime-gpu==1.21.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oitf0QplRoll",
        "outputId": "81897a41-a7c4-486e-f07c-6ea9485fab2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping onnxruntime as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: onnxruntime-gpu 1.21.0\n",
            "Uninstalling onnxruntime-gpu-1.21.0:\n",
            "  Successfully uninstalled onnxruntime-gpu-1.21.0\n",
            "Collecting onnxruntime-gpu==1.21.0\n",
            "  Using cached onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from onnxruntime-gpu==1.21.0) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu==1.21.0) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/miniconda/envs/py310/lib/python3.10/site-packages (from sympy->onnxruntime-gpu==1.21.0) (1.3.0)\n",
            "Using cached onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "Installing collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python emgaxo/MNIST_Tutorial_SW/07_accuracy_tester_ApproxQGemm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JldoUIA2RpQD",
        "outputId": "bee4216e-e9e7-4869-b395-e678eb1e2b3e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/emgaxo/MNIST_Tutorial_SW/07_accuracy_tester_ApproxQGemm.py\", line 13, in <module>\n",
            "    accuracy, precision, recall, f1  = check_accuracy(modified_model, True, \n",
            "  File \"/usr/local/miniconda/envs/py310/lib/python3.10/site-packages/emgaxo/AccuracyTester/AccuracyTester.py\", line 184, in check_accuracy\n",
            "    raise FileNotFoundError(f\"Custom op library not found at: {custom_op_library_path}\")\n",
            "FileNotFoundError: Custom op library not found at: /usr/local/miniconda/envs/py310/lib/python3.10/site-packages/emgaxo/CustomOpLib/libcustom_op_library.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oQwcIpbIRr7b"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}